{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS_multiview.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TKpgXRmB0bP",
        "outputId": "e34319f9-58fa-4fd6-92e9-e894b7e7e293",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# %cd ../..\n",
        "!rm -rf CS-summ-Multi-view/\n",
        "!git clone https://github.com/ad6398/CS-summ-Multi-view"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CS-summ-Multi-view'...\n",
            "remote: Enumerating objects: 576, done.\u001b[K\n",
            "remote: Counting objects: 100% (576/576), done.\u001b[K\n",
            "remote: Compressing objects: 100% (426/426), done.\u001b[K\n",
            "remote: Total 576 (delta 137), reused 564 (delta 128), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (576/576), 7.33 MiB | 18.81 MiB/s, done.\n",
            "Resolving deltas: 100% (137/137), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqWD_EdGCixG"
      },
      "source": [
        "md = \"/content/CS-summ-Multi-view/\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2w9pc3Kuo36"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA5uu7RVwMU9"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ02BSgyDlst",
        "outputId": "e1281c08-ffdb-43a9-a23b-bac5bac3e5ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "\n",
        "def convert_data(sd= md+\"data/\"):\n",
        "  csv_data= pd.read_csv(\"/content/drive/My Drive/ml_data/code_switch/Dataset.csv\")\n",
        "  print(csv_data)\n",
        "  def write_data(dt,s,e):\n",
        "    fp= open(sd+dt+\".json\",'w')\n",
        "    td= []\n",
        "    for i in range(s,e):\n",
        "      nd= {}\n",
        "      # nd['id']= dt+\"_\"+str(i)\n",
        "      nd['id']= csv_data['id'][i]\n",
        "      nd['summary']= csv_data['summary-english'][i]\n",
        "      nd['dialogue'] = csv_data['dialogue-hinglish'][i]\n",
        "      td.append(nd)\n",
        "    json.dump(td, fp)\n",
        "    fp.close()\n",
        "  \n",
        "  write_data(\"val\", 0,500)\n",
        "  write_data(\"test\", 500, 1000)\n",
        "  write_data(\"train\", 1000,len(csv_data))\n",
        "\n",
        "\n",
        "\n",
        "convert_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            id  ...                                  dialogue-hinglish\n",
            "0     13818513  ...  Amanda: Maine Cookies bake kiya. Kya tujeh cha...\n",
            "1     13728867  ...  Olivia: Iss election mein kisko vote kar rahe ...\n",
            "2     13681000  ...  Tim: Hi, kya chal raha hai?\\nKim: Sach bolu to...\n",
            "3     13730747  ...  Edward: Rachel, mujeh lagta hai ki mein Bella ...\n",
            "4     13728094  ...  Sam: Hey, meine rick kuch bolte hue sun liya \\...\n",
            "...        ...  ...                                                ...\n",
            "6826  13828301  ...  Tom: main Josh ko doc ke paas lekr gaya\\n Tom:...\n",
            "6827  13728591  ...  Bart: <file_photo>\\n Dean: ye foxy lady kaun h...\n",
            "6828  13730829  ...  Daniel: <file_photo>\\n Lizzy: dog ke naam ka k...\n",
            "6829  13681980  ...  Todd: Hey, get your shit together and aao yaha...\n",
            "6830  13730127  ...  Noah: Main apni grandma ko visit karne jaa rah...\n",
            "\n",
            "[6831 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-WOuX1gfq-u",
        "outputId": "b3ff37db-ba9b-4b0a-a54f-4f64edd29af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install rouge\n",
        "!pip install uts\n",
        "!pip install -U sentence-transformers\n",
        "!pip install --editable CS-summ-Multi-view/fairseq_multi_view\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install --upgrade --user hmmlearn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading https://files.pythonhosted.org/packages/43/cc/e18e33be20971ff73a056ebdb023476b5a545e744e3fc22acd8c758f1e0d/rouge-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.0\n",
            "Collecting uts\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/55/8dc06df6baf821baa45083697c3f3f54d8e84db6258fd2e8f29ada2a9bba/uts-0.0.4.tar.gz\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from uts) (1.18.5)\n",
            "Building wheels for collected packages: uts\n",
            "  Building wheel for uts (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uts: filename=uts-0.0.4-cp36-none-any.whl size=6654 sha256=c6c70263081c691cb5a4eda1c8eeb94462eee89229d50cdea616ad74d67efad7\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/a2/20/5ab318441208a96d6d92d89e017a2aa2c611486f10659a17a6\n",
            "Successfully built uts\n",
            "Installing collected packages: uts\n",
            "Successfully installed uts-0.0.4\n",
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/fd/0190080aa0af78d7cd5874e4e8e85f0bed9967dd387cf05d760832b95da9/sentence-transformers-0.3.8.tar.gz (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.7MB/s \n",
            "\u001b[?25hCollecting transformers<3.4.0,>=3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 30.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 35.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.4.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.4.0,>=3.1.0->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.4.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.8-cp36-none-any.whl size=101996 sha256=d01b23307c722931bdfab33a07dc96591214268208d3eadee09027897bb96a2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/ec/b3/d12cc8e4daf77846db6543033d3a5642f204c0320b15945647\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=74b6a99fb923657ee9f44e9567822684f0b8c95fbe827e562bc02e39d0e2e98c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.8 sentencepiece-0.1.94 tokenizers-0.8.1rc2 transformers-3.3.1\n",
            "Obtaining file:///content/CS-summ-Multi-view/fairseq_multi_view\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.14.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (0.29.21)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (2019.12.20)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq==0.9.0) (4.41.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq==0.9.0) (2.20)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==0.9.0) (0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==0.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq==0.9.0) (0.16.0)\n",
            "Installing collected packages: portalocker, sacrebleu, fairseq\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq portalocker-2.0.0 sacrebleu-1.4.14\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting hmmlearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/49/9e9a89cee24b26ef6afec5abbd5eb9cf14632855f32b999389873ecb1b4e/hmmlearn-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (361kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.10 in /usr/local/lib/python3.6/dist-packages (from hmmlearn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->hmmlearn) (0.17.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2RwCzzNmGFT",
        "outputId": "f663c3bc-8853-485a-e4cb-8f702642f6d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd CS-summ-Multi-view/data/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS-summ-Multi-view/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "490vRyp3Dlz4",
        "outputId": "6766ff2e-9c9d-40f0-c92c-7b7d92fcad4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python sentence_embeddings.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 06:27:02.621655: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "gpu num:  1\n",
            "100% 405M/405M [00:24<00:00, 16.7MB/s]\n",
            "HBox(children=(FloatProgress(value=0.0, max=5831.0), HTML(value='')))\n",
            "\n",
            "sentence_embeddings.py:40: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  for i in tqdm(range(0, len(sent))):\n",
            "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))\n",
            "\n",
            "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPevqTbKCi1n"
      },
      "source": [
        "!python topic_segment.py"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXwBKb3UkGDu",
        "outputId": "813e9f66-1b17-4249-b63d-6d85818017e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python stage_segmentation.py"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         1   -34968644.6562             +nan\n",
            "         2   -34176271.1141     +792373.5421\n",
            "         3   -34088464.0352      +87807.0790\n",
            "         4   -34050692.3263      +37771.7089\n",
            "         5   -34029528.2572      +21164.0691\n",
            "         6   -34016619.5393      +12908.7179\n",
            "         7   -34007320.3608       +9299.1785\n",
            "         8   -33999397.3974       +7922.9635\n",
            "         9   -33993141.9196       +6255.4777\n",
            "        10   -33988151.8533       +4990.0663\n",
            "        11   -33983317.7493       +4834.1040\n",
            "        12   -33978751.8546       +4565.8947\n",
            "        13   -33973838.5345       +4913.3201\n",
            "        14   -33969068.8187       +4769.7158\n",
            "        15   -33965137.4611       +3931.3577\n",
            "        16   -33961640.9969       +3496.4642\n",
            "        17   -33959036.4033       +2604.5936\n",
            "        18   -33956921.9432       +2114.4600\n",
            "        19   -33955236.4656       +1685.4777\n",
            "        20   -33953980.1759       +1256.2897\n",
            "        21   -33953090.3415        +889.8344\n",
            "        22   -33952539.6700        +550.6715\n",
            "        23   -33952234.1706        +305.4994\n",
            "        24   -33951984.2456        +249.9250\n",
            "        25   -33951750.5194        +233.7262\n",
            "        26   -33951611.5367        +138.9827\n",
            "        27   -33951526.1472         +85.3895\n",
            "        28   -33951460.0641         +66.0831\n",
            "        29   -33951413.2821         +46.7820\n",
            "        30   -33951373.1342         +40.1479\n",
            "        31   -33951336.4145         +36.7197\n",
            "        32   -33951293.6260         +42.7885\n",
            "        33   -33951251.4850         +42.1410\n",
            "        34   -33951220.6790         +30.8060\n",
            "        35   -33951200.1871         +20.4919\n",
            "        36   -33951182.3439         +17.8432\n",
            "        37   -33951166.6284         +15.7155\n",
            "        38   -33951151.0818         +15.5466\n",
            "        39   -33951140.8569         +10.2250\n",
            "        40   -33951130.4992         +10.3577\n",
            "        41   -33951117.3930         +13.1062\n",
            "        42   -33951108.6275          +8.7655\n",
            "        43   -33951102.6897          +5.9378\n",
            "        44   -33951097.3502          +5.3395\n",
            "        45   -33951093.7161          +3.6341\n",
            "        46   -33951090.9501          +2.7660\n",
            "        47   -33951088.7735          +2.1766\n",
            "        48   -33951086.6921          +2.0813\n",
            "        49   -33951084.9456          +1.7465\n",
            "        50   -33951083.6306          +1.3150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUBNQ8pBkGI_",
        "outputId": "97854c27-53c0-45c5-e9c0-c9f3dd2706d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python read_labels.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5825\n",
            "5825\n",
            "5825\n",
            "5825\n",
            "5825\n",
            "5825\n",
            "5825\n",
            "5825\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n",
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd-MnMs0kGRw",
        "outputId": "12096a20-67d0-4a28-8d10-2f580c57bfa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ../train_sh/\n",
        "!wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json'\n",
        "!wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe'\n",
        "!wget -N 'https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt'"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CS-summ-Multi-view/train_sh\n",
            "--2020-11-15 06:46:18--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘encoder.json’ not modified on server. Omitting download.\n",
            "\n",
            "--2020-11-15 06:46:18--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘vocab.bpe’ not modified on server. Omitting download.\n",
            "\n",
            "--2020-11-15 06:46:19--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘dict.txt’ not modified on server. Omitting download.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qasENNdJgZv7"
      },
      "source": [
        "!chmod +x bpe.sh\n",
        "!./bpe.sh\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWpBvgN-hNWv",
        "outputId": "1ce00cb6-e7db-4564-8a37-5eb7002bdd93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!chmod +x binarize.sh \n",
        "!./binarize.sh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 06:47:52 | INFO | fairseq_cli.preprocess | Namespace(T=1, align_suffix=None, alignfile=None, all_gather_list_size=16384, balance=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='cnn_dm-bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_weight=1, memory_efficient_fp16=False, min_loss_scale=0.0001, multi_views=False, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=14632, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir='', testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='../data/train_sent_c99_label.bpe', user_dir=None, validpref='../data/val_sent_c99_label.bpe', workers=60)\n",
            "2020-11-15 06:47:52 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50263 types\n",
            "2020-11-15 06:48:02 | INFO | fairseq_cli.preprocess | [source] ../data/train_sent_c99_label.bpe.source: 5825 sents, 1244975 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:02 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50263 types\n",
            "2020-11-15 06:48:04 | INFO | fairseq_cli.preprocess | [source] ../data/val_sent_c99_label.bpe.source: 500 sents, 103321 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:04 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50263 types\n",
            "2020-11-15 06:48:07 | INFO | fairseq_cli.preprocess | [target] ../data/train_sent_c99_label.bpe.target: 5825 sents, 153278 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:07 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50263 types\n",
            "2020-11-15 06:48:09 | INFO | fairseq_cli.preprocess | [target] ../data/val_sent_c99_label.bpe.target: 500 sents, 13032 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:09 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to cnn_dm-bin/\n",
            "2020-11-15 06:48:10 | INFO | fairseq_cli.preprocess | Namespace(T=1, align_suffix=None, alignfile=None, all_gather_list_size=16384, balance=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='cnn_dm-bin_2/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=1000, lr_scheduler='fixed', lr_weight=1, memory_efficient_fp16=False, min_loss_scale=0.0001, multi_views=False, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer='nag', padding_factor=8, seed=14632, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir='', testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, trainpref='../data/train_sent_trans_cons_label.bpe', user_dir=None, validpref='../data/val_sent_trans_cons_label.bpe', workers=60)\n",
            "2020-11-15 06:48:11 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50263 types\n",
            "2020-11-15 06:48:20 | INFO | fairseq_cli.preprocess | [source] ../data/train_sent_trans_cons_label.bpe.source: 5825 sents, 1177799 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:20 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50263 types\n",
            "2020-11-15 06:48:23 | INFO | fairseq_cli.preprocess | [source] ../data/val_sent_trans_cons_label.bpe.source: 500 sents, 97946 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:23 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50263 types\n",
            "2020-11-15 06:48:26 | INFO | fairseq_cli.preprocess | [target] ../data/train_sent_trans_cons_label.bpe.target: 5825 sents, 153278 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:26 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50263 types\n",
            "2020-11-15 06:48:28 | INFO | fairseq_cli.preprocess | [target] ../data/val_sent_trans_cons_label.bpe.target: 500 sents, 13032 tokens, 0.0% replaced by <unk>\n",
            "2020-11-15 06:48:28 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to cnn_dm-bin_2/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hot_NWV2wN6Z",
        "outputId": "89d859bd-608e-4d96-cf39-8777411a3a31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz\n",
        "!tar -xf bart.large.tar.gz"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-15 06:48:28--  https://dl.fbaipublicfiles.com/fairseq/models/bart.large.tar.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3699866548 (3.4G) [application/x-tar]\n",
            "Saving to: ‘bart.large.tar.gz’\n",
            "\n",
            "bart.large.tar.gz   100%[===================>]   3.45G  55.2MB/s    in 63s     \n",
            "\n",
            "2020-11-15 06:49:31 (56.1 MB/s) - ‘bart.large.tar.gz’ saved [3699866548/3699866548]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFeaE56ohNVC",
        "outputId": "5caa9b6f-c27c-48d1-c67a-84a037895f26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!chmod +x train_multi_view.sh\n",
        "!./train_multi_view.sh"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 09:56:54 | INFO | fairseq_cli.train | Namespace(T=0.2, activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='bart_large', attention_dropout=0.1, balance=True, best_checkpoint_metric='loss', bpe=None, broadcast_buffers=False, bucket_cap_mb=25, clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='cnn_dm-bin_2', dataset_impl=None, ddp_backend='no_c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layer_wise_attention=False, layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, log_format=None, log_interval=1000, lr=[3e-05], lr_scheduler='polynomial_decay', lr_weight=1000.0, max_epoch=0, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=900, max_tokens_valid=900, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, multi_views=True, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_token_positional_embeddings=False, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, relu_dropout=0.0, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='bart.large/model.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, seed=14632, sentence_avg=False, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, source_lang='source', target_lang='target', task='translation', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=5000, train_subset='train', truncate_source=True, update_freq=[32], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_interval=1, warmup_updates=200, weight_decay=0.01)\n",
            "2020-11-15 09:56:54 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types\n",
            "2020-11-15 09:56:54 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types\n",
            "2020-11-15 09:56:54 | INFO | fairseq.data.data_utils | loaded 500 examples from: cnn_dm-bin_2/valid.source-target.source\n",
            "2020-11-15 09:56:54 | INFO | fairseq.data.data_utils | loaded 500 examples from: cnn_dm-bin/valid.source-target.source\n",
            "2020-11-15 09:56:54 | INFO | fairseq.data.data_utils | loaded 500 examples from: cnn_dm-bin_2/valid.source-target.target\n",
            "2020-11-15 09:56:54 | INFO | fairseq.tasks.translation | cnn_dm-bin_2 valid source-target 500 examples\n",
            "!!! 500 500\n",
            "2020-11-15 09:57:06 | INFO | fairseq_cli.train | BARTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embed_tokens): Embedding(50264, 1024, padding_idx=1)\n",
            "    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (encoder_attn): MultiheadAttention(\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (classification_heads): ModuleDict()\n",
            "  (section_positions): LearnedPositionalEmbedding(1025, 1024, padding_idx=0)\n",
            "  (section_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (section): LSTM(1024, 1024)\n",
            "  (w_proj_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "  (w_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (w_context_vector): Linear(in_features=1024, out_features=1, bias=False)\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "2020-11-15 09:57:06 | INFO | fairseq_cli.train | model bart_large, criterion LabelSmoothedCrossEntropyCriterion\n",
            "2020-11-15 09:57:06 | INFO | fairseq_cli.train | num. model params: 416791552 (num. trained: 416791552)\n",
            "2020-11-15 09:57:11 | INFO | fairseq_cli.train | training on 1 GPUs\n",
            "2020-11-15 09:57:11 | INFO | fairseq_cli.train | max tokens per GPU = 900 and max sentences per GPU = None\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x124cf2000 @  0x7fc8b2a82b6b 0x7fc8b2aa2379 0x7fc85c4fa74e 0x7fc85c4fc7b6 0x7fc896f65ba5 0x7fc8a6c201d9 0x551555 0x5a9dac 0x50a433 0x50beb4 0x507be4 0x508ec2 0x5a4c61 0x5a4fb8 0x4e012e 0x50a461 0x50beb4 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900\n",
            "tcmalloc: large alloc 1625169920 bytes == 0x185ad4000 @  0x7fc8b2a82b6b 0x7fc8b2aa2379 0x7fc85c4fa74e 0x7fc85c4fc7b6 0x7fc896f65ba5 0x7fc8a6c201d9 0x551555 0x5a9dac 0x50a433 0x50beb4 0x507be4 0x508ec2 0x5a4c61 0x5a4fb8 0x4e012e 0x50a461 0x50beb4 0x507be4 0x588e5c 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900\n",
            "2020-11-15 09:59:05 | INFO | fairseq.trainer | loaded checkpoint bart.large/model.pt (epoch 41 @ 0 updates)\n",
            "group1: \n",
            "511\n",
            "group2: \n",
            "12\n",
            "2020-11-15 09:59:05 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n",
            "here schedule!\n",
            "2020-11-15 09:59:05 | INFO | fairseq.trainer | loading train data for epoch 0\n",
            "2020-11-15 09:59:05 | INFO | fairseq.data.data_utils | loaded 5825 examples from: cnn_dm-bin_2/train.source-target.source\n",
            "2020-11-15 09:59:05 | INFO | fairseq.data.data_utils | loaded 5825 examples from: cnn_dm-bin/train.source-target.source\n",
            "2020-11-15 09:59:05 | INFO | fairseq.data.data_utils | loaded 5825 examples from: cnn_dm-bin_2/train.source-target.target\n",
            "2020-11-15 09:59:05 | INFO | fairseq.tasks.translation | cnn_dm-bin_2 train source-target 5825 examples\n",
            "!!! 5825 5825\n",
            "2020-11-15 09:59:05 | WARNING | fairseq.data.data_utils | 14 samples have invalid sizes and will be skipped, max_positions=(900, 900), first few sample ids=[1031, 1067, 130, 1034, 2667, 2773, 1041, 1159, 3264, 1028]\n",
            "True\n",
            "epoch 001:   0% 0/50 [00:00<?, ?it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/optim/adam.py:179: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
            "epoch 001 | loss 6.943 | nll_loss 5.065 | ppl 33.467 | wps 129.2 | ups 0.04 | wpb 3052.9 | bsz 116.2 | num_updates 50 | lr 7.5e-06 | gnorm 40.651 | clip 100 | oom 0 | train_wall 1175 | wall 1297\n",
            "epoch 001 | valid on 'valid' subset | loss 4.956 | nll_loss 3.056 | ppl 8.316 | wps 371.5 | wpb 98.7 | bsz 3.8 | num_updates 50\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            "  0% 0/499 [00:00<?, ?it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [7, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [2, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "  2% 8/499 [00:05<05:25,  1.51it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "  3% 16/499 [00:07<04:31,  1.78it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "  8% 40/499 [00:20<04:00,  1.91it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 10% 48/499 [00:25<04:11,  1.79it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 13% 64/499 [00:33<03:52,  1.87it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [6, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 18% 88/499 [00:46<03:50,  1.79it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            " 22% 112/499 [00:54<02:44,  2.35it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 24% 120/499 [00:57<02:39,  2.37it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 26% 128/499 [01:02<02:54,  2.13it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 27% 136/499 [01:04<02:30,  2.42it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 29% 144/499 [01:07<02:13,  2.67it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [3, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 30% 152/499 [01:09<02:08,  2.71it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 34% 168/499 [01:16<02:11,  2.51it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [4, 8], which does not match the required output shape [1, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 35% 176/499 [01:20<02:10,  2.48it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 38% 192/499 [01:25<01:50,  2.78it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [5, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            " 42% 208/499 [01:30<01:42,  2.83it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [4].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 55% 272/499 [01:55<01:16,  2.97it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 59% 296/499 [02:02<01:04,  3.16it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 66% 328/499 [02:15<01:05,  2.62it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 85% 424/499 [02:56<00:29,  2.57it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:28<00:00,  2.39it/s]\n",
            "Val {'rouge-1': {'f': 0.36084688025728984, 'p': 0.3794377556568155, 'r': 0.378927521905809}, 'rouge-2': {'f': 0.12126614706443538, 'p': 0.12696345271206574, 'r': 0.12872283119540695}, 'rouge-l': {'f': 0.3573354398862738, 'p': 0.385568405466952, 'r': 0.36086496847271143}}\n",
            "2020-11-15 10:26:56 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 50 updates, score 4.956) (writing took 240.71093415399991 seconds)\n",
            "Test on testing set: \n",
            " 37% 184/499 [01:14<01:59,  2.64it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 42% 208/499 [01:25<02:06,  2.30it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            " 50% 248/499 [01:45<02:05,  2.00it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [7, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 88% 440/499 [03:09<00:25,  2.35it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [3, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 98% 488/499 [03:33<00:05,  2.08it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:36<00:00,  2.31it/s]\n",
            "Test {'rouge-1': {'f': 0.36319021778022464, 'p': 0.3869340544177295, 'r': 0.37550407179259887}, 'rouge-2': {'f': 0.11950464685204897, 'p': 0.1256538942092777, 'r': 0.12620077068656665}, 'rouge-l': {'f': 0.35846029187938006, 'p': 0.390389760616741, 'r': 0.35712486884239475}}\n",
            "epoch 002 | loss 4.887 | nll_loss 3.093 | ppl 8.533 | wps 80.8 | ups 0.03 | wpb 3052.9 | bsz 116.2 | num_updates 100 | lr 1.5e-05 | gnorm 2.637 | clip 100 | oom 0 | train_wall 1175 | wall 3186\n",
            "epoch 002 | valid on 'valid' subset | loss 4.685 | nll_loss 2.855 | ppl 7.236 | wps 374.2 | wpb 98.7 | bsz 3.8 | num_updates 100 | best_loss 4.685\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            "  5% 24/499 [00:12<04:30,  1.75it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [6].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 10% 48/499 [00:26<04:20,  1.73it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [9].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 80% 400/499 [02:52<00:51,  1.92it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [1], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [1].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:33<00:00,  2.33it/s]\n",
            "Val {'rouge-1': {'f': 0.3947887360079281, 'p': 0.4113674803035094, 'r': 0.41693339823496467}, 'rouge-2': {'f': 0.15011762953200306, 'p': 0.15366177691163996, 'r': 0.16222053171004472}, 'rouge-l': {'f': 0.38938857627723467, 'p': 0.4147294420866859, 'r': 0.39555112841407825}}\n",
            "2020-11-15 10:58:30 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 100 updates, score 4.685) (writing took 240.2931202639993 seconds)\n",
            "Test on testing set: \n",
            " 42% 208/499 [01:32<02:08,  2.27it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:52<00:00,  2.15it/s]\n",
            "Test {'rouge-1': {'f': 0.39036770581077856, 'p': 0.41098210979261485, 'r': 0.40965313058349523}, 'rouge-2': {'f': 0.14325218274064405, 'p': 0.1506764165472195, 'r': 0.15309511897401795}, 'rouge-l': {'f': 0.38172766911647854, 'p': 0.40817443710216567, 'r': 0.38665984249956475}}\n",
            "epoch 003 | loss 4.596 | nll_loss 2.805 | ppl 6.991 | wps 79.9 | ups 0.03 | wpb 3052.9 | bsz 116.2 | num_updates 150 | lr 2.25e-05 | gnorm 2.514 | clip 100 | oom 0 | train_wall 1175 | wall 5098\n",
            "epoch 003 | valid on 'valid' subset | loss 4.59 | nll_loss 2.776 | ppl 6.848 | wps 373.5 | wpb 98.7 | bsz 3.8 | num_updates 150 | best_loss 4.59\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            " 18% 88/499 [00:45<03:52,  1.77it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [5], which does not match the required output shape [7].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [5, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            " 24% 120/499 [00:56<02:35,  2.44it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [4], which does not match the required output shape [10].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [8, 8], which does not match the required output shape [4, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [10], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 56% 280/499 [01:59<01:18,  2.77it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [3], which does not match the required output shape [11].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:559: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=active_mask,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/search.py:81: UserWarning: An output with one or more elements was resized since it had shape [6, 8], which does not match the required output shape [2, 8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [11], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            " 61% 304/499 [02:06<01:04,  3.01it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [6], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "100% 499/499 [03:28<00:00,  2.40it/s]\n",
            "Val {'rouge-1': {'f': 0.40705037866594984, 'p': 0.4372146299711857, 'r': 0.41871927175219725}, 'rouge-2': {'f': 0.16095440589870627, 'p': 0.1710488259904821, 'r': 0.16726520130430744}, 'rouge-l': {'f': 0.39337312277209247, 'p': 0.4209359372732817, 'r': 0.39861860348814826}}\n",
            "2020-11-15 11:30:16 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 3 @ 150 updates, score 4.59) (writing took 240.6203871809994 seconds)\n",
            "Test on testing set: \n",
            "100% 499/499 [03:46<00:00,  2.20it/s]\n",
            "Test {'rouge-1': {'f': 0.40967294849317576, 'p': 0.43480283635935757, 'r': 0.42381518303216875}, 'rouge-2': {'f': 0.1602270418817454, 'p': 0.16843741156270378, 'r': 0.16966319519376127}, 'rouge-l': {'f': 0.39635038079336726, 'p': 0.42031171293722636, 'r': 0.4028751044432142}}\n",
            "epoch 004 | loss 4.369 | nll_loss 2.565 | ppl 5.916 | wps 80.2 | ups 0.03 | wpb 3052.9 | bsz 116.2 | num_updates 200 | lr 3e-05 | gnorm 3.413 | clip 100 | oom 0 | train_wall 1179 | wall 7001\n",
            "epoch 004 | valid on 'valid' subset | loss 4.549 | nll_loss 2.76 | ppl 6.776 | wps 370.9 | wpb 98.7 | bsz 3.8 | num_updates 200 | best_loss 4.549\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            "100% 499/499 [03:26<00:00,  2.41it/s]\n",
            "Val {'rouge-1': {'f': 0.4102298809875488, 'p': 0.4306668832911733, 'r': 0.4284016511334337}, 'rouge-2': {'f': 0.15921908181870645, 'p': 0.1643406830488566, 'r': 0.17102465938454675}, 'rouge-l': {'f': 0.39642664430116475, 'p': 0.4186660617935168, 'r': 0.40587026165517154}}\n",
            "2020-11-15 12:01:58 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 4 @ 200 updates, score 4.549) (writing took 240.51738439700057 seconds)\n",
            "Test on testing set: \n",
            " 10% 48/499 [00:19<03:10,  2.37it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [2], which does not match the required output shape [8].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:43<00:00,  2.24it/s]\n",
            "Test {'rouge-1': {'f': 0.41498865687505554, 'p': 0.4355888227310834, 'r': 0.43284337428967556}, 'rouge-2': {'f': 0.15757808402305665, 'p': 0.163206137099782, 'r': 0.1689505227846816}, 'rouge-l': {'f': 0.3977281772711764, 'p': 0.4193488157048422, 'r': 0.40536230751409746}}\n",
            "epoch 005 | loss 4.156 | nll_loss 2.334 | ppl 5.041 | wps 80.6 | ups 0.03 | wpb 3052.9 | bsz 116.2 | num_updates 250 | lr 2.96875e-05 | gnorm 2.262 | clip 100 | oom 0 | train_wall 1176 | wall 8896\n",
            "epoch 005 | valid on 'valid' subset | loss 4.52 | nll_loss 2.726 | ppl 6.618 | wps 372.8 | wpb 98.7 | bsz 3.8 | num_updates 250 | best_loss 4.52\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            " 61% 304/499 [02:08<01:04,  3.01it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [0].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [9], which does not match the required output shape [3].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:27<00:00,  2.40it/s]\n",
            "Val {'rouge-1': {'f': 0.41145153490222913, 'p': 0.43601280247371405, 'r': 0.42602777751268334}, 'rouge-2': {'f': 0.16247069486747137, 'p': 0.17173277688762084, 'r': 0.16983852525443172}, 'rouge-l': {'f': 0.3973124097388043, 'p': 0.42034998745678814, 'r': 0.4057893674904735}}\n",
            "2020-11-15 12:33:35 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 5 @ 250 updates, score 4.52) (writing took 240.60381921099906 seconds)\n",
            "Test on testing set: \n",
            "100% 499/499 [03:48<00:00,  2.18it/s]\n",
            "Test {'rouge-1': {'f': 0.41166670739579764, 'p': 0.42924651188616514, 'r': 0.4337850017854506}, 'rouge-2': {'f': 0.16726013090706324, 'p': 0.17394206053311603, 'r': 0.1788864138826186}, 'rouge-l': {'f': 0.40018060332336014, 'p': 0.4171352322425226, 'r': 0.41368067963402866}}\n",
            "epoch 006 | loss 3.922 | nll_loss 2.074 | ppl 4.211 | wps 80.2 | ups 0.03 | wpb 3052.9 | bsz 116.2 | num_updates 300 | lr 2.9375e-05 | gnorm 2.253 | clip 100 | oom 0 | train_wall 1176 | wall 10800\n",
            "epoch 006 | valid on 'valid' subset | loss 4.512 | nll_loss 2.716 | ppl 6.571 | wps 372.6 | wpb 98.7 | bsz 3.8 | num_updates 300 | best_loss 4.512\n",
            "here bpe NONE\n",
            "here!\n",
            "Test on val set: \n",
            " 13% 64/499 [00:36<04:14,  1.71it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [8], which does not match the required output shape [2].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            " 55% 272/499 [02:05<01:27,  2.61it/s]/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:497: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_bbsz_idx,\n",
            "/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/sequence_generator.py:505: UserWarning: An output with one or more elements was resized since it had shape [7], which does not match the required output shape [5].This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at  /pytorch/aten/src/ATen/native/Resize.cpp:19.)\n",
            "  out=eos_scores,\n",
            "100% 499/499 [03:43<00:00,  2.23it/s]\n",
            "Val {'rouge-1': {'f': 0.4157369733362083, 'p': 0.42182160178131517, 'r': 0.45037322740542585}, 'rouge-2': {'f': 0.16815604313277607, 'p': 0.169756872692117, 'r': 0.18368159266473713}, 'rouge-l': {'f': 0.40498797278813664, 'p': 0.41303022427848896, 'r': 0.42896278412316424}}\n",
            "2020-11-15 13:05:33 | INFO | fairseq.checkpoint_utils | saved checkpoint checkpoints/checkpoint_best.pt (epoch 6 @ 300 updates, score 4.512) (writing took 240.41929473300115 seconds)\n",
            "Test on testing set: \n",
            "100% 499/499 [03:53<00:00,  2.13it/s]\n",
            "Test {'rouge-1': {'f': 0.4180930023850601, 'p': 0.4191400034956905, 'r': 0.4571210181091564}, 'rouge-2': {'f': 0.1725252499749064, 'p': 0.1724692118495714, 'r': 0.19134513632011593}, 'rouge-l': {'f': 0.4061415308466624, 'p': 0.4094950618441587, 'r': 0.4319940248370492}}\n",
            "epoch 007:  22% 11/50 [04:21<15:29, 23.84s/it, loss=3.736, nll_loss=1.864, ppl=3.639, wps=33.1, ups=0.01, wpb=3007.8, bsz=115.1, num_updates=311, lr=2.93063e-05, gnorm=2.232, clip=100, oom=0, train_wall=259, wall=11800]Traceback (most recent call last):\n",
            "  File \"train.py\", line 11, in <module>\n",
            "    cli_main()\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq_cli/train.py\", line 439, in cli_main\n",
            "    main(args)\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq_cli/train.py\", line 112, in main\n",
            "    train(args, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 52, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq_cli/train.py\", line 302, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 52, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/trainer.py\", line 430, in train_step\n",
            "    sample, self.model, self.criterion, self.optimizer, ignore_grad\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/tasks/fairseq_task.py\", line 298, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/content/CS-summ-Multi-view/fairseq_multi_view/fairseq/optim/fairseq_optimizer.py\", line 91, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 221, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 132, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3U0m-NCNBOt"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2WDNvyFNC4R"
      },
      "source": [
        "Just update the code of search.py from 'torch.div(self.indices_buf, vocab_size, out=self.beams_buf)' to 'torch.floor_divide(self.indices_buf, vocab_size, out=self.beams_buf)'"
      ]
    }
  ]
}