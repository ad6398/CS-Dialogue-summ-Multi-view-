# -*- coding: utf-8 -*-
"""Sentence_Embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1907dqvEwmqI4rxLw8TTgkn3ACNLFQcY7
"""

from sentence_transformers import SentenceTransformer
import torch

import os
os.environ['CUDA_VISIBLE_DEVICES'] = '3'
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
n_gpu = torch.cuda.device_count()
print("gpu num: ", n_gpu)

embedder = SentenceTransformer('bert-base-nli-stsb-mean-tokens')

import json
from tqdm import tqdm_notebook as tqdm
import pickle

def encode_conversation(profix):
    with open(profix + '.json', encoding = 'utf8') as json_file:
        data = json.load(json_file)
    
    sent = []
    for i in range(0, len(data)):
        if len(data[i]['dialogue'].split('\r\n')) > 1:
            sentences = data[i]['dialogue'].split('\r\n')
        else:
            sentences = data[i]['dialogue'].split('\n')
        sent.append(sentences)
        
    
    embeddings = []
    with torch.no_grad():
        for i in tqdm(range(0, len(sent))):
            #tokens_input = tokenize_conv(sent[i]).cuda()
            embedding = embedder.encode(sent[i])

            embeddings.append(embedding)
            
    with open(profix + '_sentence_transformer.pkl', 'wb') as f:
        pickle.dump(embeddings, f)
    
        
    return embeddings

embeddings = encode_conversation('train')

embeddings = encode_conversation('val')

embeddings = encode_conversation('test')





