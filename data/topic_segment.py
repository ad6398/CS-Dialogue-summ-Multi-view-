# -*- coding: utf-8 -*-
"""Topic_Segment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16N0hZ0fW6oyIXhjh2WZBV4BiRwd4ctIh
"""
from tqdm import tqdm_notebook as tqdm
import uts

import json
with open('train.json', encoding = 'utf8') as json_file:
    train = json.load(json_file)
with open('test.json', encoding = 'utf8') as json_file:
    test = json.load(json_file)
with open('val.json', encoding = 'utf8') as json_file:
    val = json.load(json_file)

import gensim

def remove_name(s):
    temp = ""
    flag = 0
    for i in range(0, len(s)):
        if s[i] == ':':
            flag = 1
            continue
        if flag == 1:
            temp += s[i]
    return temp

sent = []
for data in (train, test, val):
    for i in tqdm(range(0, len(data))):
        if len(data[i]['dialogue'].split('\r\n')) > 1:
            sentences = data[i]['dialogue'].split('\r\n')
        else:
            sentences = data[i]['dialogue'].split('\n')
        sent.append(sentences)

sent[0]

import string
from nltk.tokenize import word_tokenize
table = str.maketrans('', '', string.punctuation)
sentences = []
for i in tqdm(range(0, len(sent))):
    for s in sent[i]:
        temp_sent = remove_name(s)
        tokens = word_tokenize(temp_sent)
        tokens = [w.lower() for w in tokens]
        stripped = [w.translate(table) for w in tokens]
        sentences.append(stripped)

from C99 import C99

import pickle
with open('train_sentence_transformer.pkl', 'rb') as f:
    train = pickle.load(f)
with open('val_sentence_transformer.pkl', 'rb') as f:
    val = pickle.load(f)
with open('test_sentence_transformer.pkl', 'rb') as f:
    test = pickle.load(f)





def encode_convs(profix):
    model = C99(window = 4, std_coeff = 1)
    sent_label = []
    with open(profix+"_sentence_transformer.pkl", 'rb') as f:
        data = pickle.load(f)
    for i in tqdm(range(0, len(data))):
        boundary = model.segment(data[i])
        temp_labels = []
        l = 0
        for j in range(0, len(boundary)):
            if boundary[j] == 1:
                l += 1
            temp_labels.append(l)
        sent_label.append(temp_labels)
    
    with open(profix + '_sent_c99_label.pkl', 'wb') as f:
        pickle.dump(sent_label, f)
    
    return sent_label

l = encode_convs('train')

l = encode_convs('val')

l = encode_convs('test')





